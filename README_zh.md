# mPLUG-OwlğŸ¦‰: Modularization Empowers Large Language Models with Multimodality
Qinghao Ye*, Haiyang Xu*, Guohai Xu*, Jiabo Ye, Ming Yanâ€ , Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, Chenliang Li, Yuanhong Xu, Hehong Chen, Junfeng Tian, Qian Qi, Ji Zhang, Fei Huang

**é˜¿é‡Œå·´å·´é›†å›¢ï¼Œè¾¾æ‘©é™¢**

*Equal Contribution; â€  Corresponding Author

[![](assets/Demo-ModelScope-brightgreen.svg)](https://modelscope.cn/studios/damo/mPLUG-Owl/summary)
[![](assets/LICENSE-Apache%20License-blue.svg)](https://github.com/X-PLUG/mPLUG-Owl/blob/main/LICENSE)
[![](assets/Paper-PDF-orange.svg)](http://mm-chatgpt.oss-cn-zhangjiakou.aliyuncs.com/mplug_owl_demo/released_checkpoint/mPLUG_Owl_paper.pdf)
[![](assets/Paper-Arxiv-orange.svg)](https://arxiv.org/abs/2304.14178)

[English](README.md) | ç®€ä½“ä¸­æ–‡
<hr>

<img src="http://mm-chatgpt.oss-cn-zhangjiakou.aliyuncs.com/mplug_owl_demo/released_checkpoint/sample.gif"  width="60%">


## ç¤ºä¾‹
![Training paradigm and model overview](assets/case_1.png "Training paradigm and model overview")
![Training paradigm and model overview](assets/case_2.png "Training paradigm and model overview")

## æœ€æ–°æ›´æ–°

* æˆ‘ä»¬åœ¨Modelscopeä¸Šæä¾›äº†ä¸€ä¸ª[åœ¨çº¿Demo](https://modelscope.cn/studios/damo/mPLUG-Owl/summary)ä¾›å¤§å®¶ä½“éªŒã€‚
* æˆ‘ä»¬å¼€æ”¾äº†mPLUG-OwlğŸ¦‰ï¼Œä»¥åŠæ¨ç†ä»£ç å’ŒäºŒé˜¶æ®µå¾®è°ƒå‚æ•°ã€‚

## äº®ç‚¹ç‰¹è‰²
* ä¸€ç§é¢å‘å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„æ¨¡å—åŒ–çš„è®­ç»ƒèŒƒå¼ã€‚
* èƒ½å­¦ä¹ ä¸è¯­è¨€ç©ºé—´ç›¸é€‚åº”çš„è§†è§‰çŸ¥è¯†ï¼Œå¹¶æ”¯æŒåœ¨å¤šæ¨¡æ€åœºæ™¯ä¸‹è¿›è¡Œå¤šè½®å¯¹è¯ã€‚
* æ¶Œç°å¤šå›¾å…³ç³»ç†è§£ï¼Œåœºæ™¯æ–‡æœ¬ç†è§£å’ŒåŸºäºè§†è§‰çš„æ–‡æ¡£ç†è§£ç­‰èƒ½åŠ›ã€‚
* æå‡ºäº†é’ˆå¯¹è§†è§‰ç›¸å…³æŒ‡ä»¤çš„æµ‹è¯„é›†**OwlEval**ï¼Œç”¨ä»¥è¯„ä¼°å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„å¯¹å¸¦æœ‰è§†è§‰ä¿¡æ¯ä¸Šä¸‹æ–‡çš„ç†è§£èƒ½åŠ›ã€‚

![Training paradigm and model overview](assets/model.png "Training paradigm and model overview")

## åœ¨çº¿Demo
[ModelScopeå¹³å°ä¸Šçš„åœ¨çº¿Demo](https://www.modelscope.cn/studios/damo/mPLUG-Owl/summary)

![](assets/modelscope.png)
## é¢„è®­ç»ƒå‚æ•°
|Model|Phase|Download link|
|-|-|-|
|mPLUG-Owl 7B|Pre-training|[ä¸‹è½½é“¾æ¥](http://mm-chatgpt.oss-cn-zhangjiakou.aliyuncs.com/mplug_owl_demo/released_checkpoint/pretrained.pth)|
|mPLUG-Owl 7B|Instruction tuning|[ä¸‹è½½é“¾æ¥](http://mm-chatgpt.oss-cn-zhangjiakou.aliyuncs.com/mplug_owl_demo/released_checkpoint/pretrained.pth)|
|Tokenizer model|N/A|[ä¸‹è½½é“¾æ¥](http://mm-chatgpt.oss-cn-zhangjiakou.aliyuncs.com/mplug_owl_demo/released_checkpoint/tokenizer.model)|
## ä½¿ç”¨
### å®‰è£…ä¾èµ–
æ ¸å¿ƒç»„ä»¶:
* PyTorch=1.12.1
* transformers=4.28.1
* [Apex](https://github.com/NVIDIA/apex)
* einops
* icecream
* flask
* ruamel.yaml
* uvicorn 
* fastapi
* markdown2
* gradio

ä½ ä¹Ÿå¯ä»¥æ ¹æ®æˆ‘ä»¬å¯¼å‡ºçš„```env.yaml```æ¥å‡†å¤‡ä½ çš„ç¯å¢ƒã€‚

### æœ¬åœ°éƒ¨ç½²Demo
æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæ˜“æ‰©å±•çš„è„šæœ¬æ¥ä¸€é”®éƒ¨ç½²æœ¬åœ°Demoï¼Œä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œä¿®æ”¹ã€‚
```Bash
python -m server_mplug.owl_demo --debug --port 6363 --checkpoint_path 'your checkpoint path' --tokenizer_path 'your tokenizer path'
```
### æ¨ç†
å¦‚æœè¦å®ç°è‡ªå®šä¹‰çš„æ¨ç†ï¼Œå¯ä»¥å‚è€ƒä»¥ä¸‹æ­¥éª¤ã€‚

æ„å»ºmodel, tokenizer, img_processor
```Python
from interface import get_model
model, tokenizer, img_processor = get_model(
        checkpoint_path='checkpoint path', tokenizer_path='tokenizer path')
```
å‡†å¤‡æ¨¡å‹è¾“å…¥
```Python
# We use a human/AI template to organize the context as a multi-turn conversation.
# <image> denotes an image placehold.
prompts = [
'''The following is a conversation between a curious human and AI assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.
Human: <image>
Human: Explain why this meme is funny.
AI: ''']

# The image paths should be placed in the image_list and kept in the same order as in the prompts.
# We support urls, local file paths and base64 string. You can custom the pre-process of images by modifying the mplug_owl.modeling_mplug_owl.ImageProcessor
image_list = ['https://xxx.com/image.jpg',]
```
è·å–æ¨¡å‹å›å¤
```Python
# generate kwargs (the same in transformers) can be passed in the do_generate()
from interface import do_generate
sentence = do_generate(prompts, image_list, model, tokenizer,
                               img_processor, max_length=512, top_k=5, do_sample=True)
```
## æ€§èƒ½æ¯”è¾ƒ
æˆ‘ä»¬å±•ç¤ºäº†50ä¸ªå•è½®å¯¹è¯ï¼ˆå·¦ï¼‰å’Œ52ä¸ªå¤šè½®å¯¹è¯ï¼ˆå³ï¼‰åœ¨äººå·¥è¯„ä¼°æŒ‡æ ‡ä¸‹ï¼ŒmPLUG-Owlå’ŒåŸºçº¿æ–¹æ³•çš„æ¯”è¾ƒç»“æœã€‚A/B/C/Dè¡¨ç¤ºè¯„åˆ†äººå‘˜å¯¹æ¯ä¸ªå›å¤çš„è¯„çº§ã€‚

![Comparison Results](assets/mPLUG_Owl_compare_result_s&mturn.png)

## å³å°†å‘å¸ƒçš„å†…å®¹

- [ ] æŒ‡ä»¤å¾®è°ƒä»£ç ã€‚
- [ ] å¤šè¯­è¨€æ”¯æŒ
- [ ] è§†è§‰ç›¸å…³æŒ‡ä»¤çš„æµ‹è¯„é›†**OwlEval**

## ç›¸å…³é¡¹ç›®

* [LLaMA](https://github.com/facebookresearch/llama). å¼€æºçš„å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ç³»åˆ—ã€‚
* [Baize](https://github.com/project-baize/baize-chatbot). ä½¿ç”¨LoRAåœ¨10ä¸‡ä¸ªé€šè¿‡è®©ChatGPTè‡ªèŠç”Ÿæˆçš„å¯¹è¯ä¸Šè¿›è¡Œè®­ç»ƒçš„å¼€æºèŠå¤©æ¨¡å‹ã€‚
* [Alpaca](https://github.com/tatsu-lab/stanford_alpaca). ä»7B LLaMAæ¨¡å‹ä¸Šè¿›è¡Œå¾®è°ƒè®­ç»ƒçš„ï¼Œç”¨äº52Kä¸ªæŒ‡ä»¤æ•°æ®çš„æ¨¡å‹ã€‚
* [LoRA](https://github.com/microsoft/LoRA). å³æ’å³ç”¨çš„æ¨¡å—ï¼Œå¯ä»¥æå¤§åœ°å‡å°‘ä¸‹æ¸¸ä»»åŠ¡çš„å¯è®­ç»ƒå‚æ•°æ•°é‡ã€‚
* [LLaVA](https://github.com/haotian-liu/LLaVA). ç»è¿‡è§†è§‰æŒ‡ä»¤è°ƒæ•´çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥å®ç°GPT4çº§åˆ«çš„èƒ½åŠ›ã€‚
* [mPLUG](https://github.com/alibaba/AliceMind/tree/main/mPLUG). è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ï¼Œå¯ä»¥ç”¨äºè·¨æ¨¡æ€ç†è§£å’Œç”Ÿæˆã€‚
* [mPLUG-2](https://github.com/alibaba/AliceMind). å…·æœ‰æ¨¡å—åŒ–è®¾è®¡çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œå¯å‘äº†æˆ‘ä»¬çš„é¡¹ç›®ã€‚

## å¼•ç”¨
å¦‚æœæˆ‘ä»¬çš„å·¥ä½œå¯¹ä½ æœ‰å¸®åŠ©ï¼Œå¯ä»¥è€ƒè™‘ç»™æˆ‘ä»¬çš„ä»“åº“ç‚¹ä¸ªstar & å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ã€‚
```
@article{ye2023mplugowl,
  title={mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality},
  author={Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yanâ€ , Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, Chenliang Li, Yuanhong Xu, Hehong Chen, Junfeng Tian, Qian Qi, Ji Zhang, Fei Huang},
  year={2023}
}
```